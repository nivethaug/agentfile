from datetime import datetime
import json
import socketio
import asyncio
import subprocess
import psutil
import logging
from logging.handlers import TimedRotatingFileHandler
from crontab import CronTab
import uuid
import ast
import aiofiles
import shutil
from dotenv import load_dotenv
import os
import pathlib
from pathlib import Path
import aiohttp
import tempfile
import zipfile
import re
import base64
from typing import Optional, Dict, Any, List, Union, Tuple

# RSA imports
from cryptography.hazmat.primitives import serialization, hashes
from cryptography.hazmat.primitives.asymmetric import padding

DEFAULT_DB_FILENAME = "credentials.db"


PM2_PROCESS_PREFIX = "bg"



load_dotenv()  # âœ… Make sure this is called before os.getenv()




# === CONFIG ===
SERVER_URL = "https://agentapi.algobillionaire.com"
AGENT_ID = os.getenv('AGENT_ID', 'agent-42e200f3-9cd6-44ee-a66a-0bab14d3490c')
AUTH_TOKEN = "bf6c405b-2901-48f3-8598-b6f1ef0b2e5a"

HOME_DIR = os.getenv("HOME_DIR", os.path.expanduser("~"))
MACHINE_ID = os.getenv("MACHINE_ID", str(uuid.getnode()))
KEY_DIR = os.path.join(HOME_DIR, "keys")
pub_path = os.path.join(KEY_DIR, "rsa_public.pem")
priv_path = os.path.join(KEY_DIR, "rsa_private.pem")
SCRIPT_DIR = os.path.join(HOME_DIR, "scripts")
LOG_BASE_DIR = os.path.join(HOME_DIR, "logs")
VENV_BASE_DIR = os.path.join(HOME_DIR, "venvalgobn")  # fixed from relative
MAX_FILE_SIZE_KB = 250
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_KB * 1024

# === SETUP ===
os.makedirs(SCRIPT_DIR, exist_ok=True)
os.makedirs(LOG_BASE_DIR, exist_ok=True)
os.makedirs(VENV_BASE_DIR, exist_ok=True)

sio = socketio.AsyncClient()
logger = None

def setup_logger(agent_id: str, script_id: str, mode: str = "run", cron_id: str = None) -> logging.Logger:
    log_dir = os.path.join(LOG_BASE_DIR, agent_id, script_id)
    if cron_id:
        log_dir = os.path.join(LOG_BASE_DIR, cron_id)
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"{mode}.log")

    logger_name = f"{agent_id}_{script_id}_{mode}"
    if cron_id:
        logger_name = f"{cron_id}_{mode}"
    logger = logging.getLogger(logger_name)
    logger.setLevel(logging.INFO)
    logger.propagate = False  # Prevent double logging

    if not logger.handlers:
        handler = TimedRotatingFileHandler(log_file, when="D", interval=1, backupCount=10)
        formatter = logging.Formatter('[%(asctime)s] %(levelname)s: %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)

    return logger

@sio.event
async def connect():
    print("âœ… Connected to server")
    await sio.emit("register_agent", {
        "agent_id": AGENT_ID,
        "auth": AUTH_TOKEN,
        "machine_id": MACHINE_ID
    })

@sio.event
async def disconnect():
    print("âŒ Disconnected from server")



def generate_requirements(script_dir, req_output_path, logger=None):
    os.makedirs(os.path.dirname(req_output_path), exist_ok=True)

    try:
        res = subprocess.run(
            ["pipreqs", script_dir, "--force", "--savepath", req_output_path],
            capture_output=True, text=True
        )

        if res.returncode != 0:
            err = res.stderr.strip() or res.stdout.strip() or "unknown error"
            if logger:
                logger.error(f"[â›”] pipreqs failed: {err}")
            else:
                print(f"[â›”] pipreqs failed: {err}")
        else:
            msg = f"[ðŸ“¦] install.txt generated at {req_output_path}"
            if logger:
                logger.info(msg)
            else:
                print(msg)

    except FileNotFoundError:
        err = "pipreqs command not found. Did you install it in this environment?"
        if logger:
            logger.error(f"[â›”] {err}")
        else:
            print(f"[â›”] {err}")



@sio.on("upload_script")
async def on_upload_script(data):
    try:
        user_id = data['agent_id']
        filename = data['filename']
        content = data['content']

        # âœ… Unique script folder
        script_id = str(uuid.uuid4())
        script_dir = os.path.join(SCRIPT_DIR, user_id, script_id)
        os.makedirs(script_dir, exist_ok=True)

        script_path = os.path.join(script_dir, filename)
        # âœ… Size check
        content_size = len(content.encode('utf-8'))
        if content_size > MAX_FILE_SIZE_BYTES:
            return {
                "status": "error",
                "log": f"Script too large. Max allowed is {MAX_FILE_SIZE_KB} KB."
            }
        try:
            # Safely decode escaped string (works for content like `"line1\\nline2"` etc.)
            cleaned = ast.literal_eval(f'"{content}"')
        except Exception as e:
            raise ValueError("Failed to decode script content") from e
        # âœ… Save script
        with open(script_path, "w") as f:
            f.write(cleaned)
        os.chmod(script_path, 0o755)
        print(f"[ðŸ“¥] Script saved: {filename} ({content_size} bytes) at {script_path}")
        logger = setup_logger(AGENT_ID, script_id, "run")
        # âœ… Create venv (per-agent)
        user_venv_path = os.path.join(VENV_BASE_DIR, user_id)
        if not os.path.exists(user_venv_path):
            subprocess.run(["python3", "-m", "venv", user_venv_path], check=True)
            logger.info(f"[âœ…] Created venv for user: {user_id}")
            print(f"[âœ…] Created venv for user: {user_id}")

        # âœ… Generate install.txt
        req_output_path = os.path.join(script_dir, "install.txt")
        generate_requirements(script_dir, req_output_path, logger)
        logger.info(f"[ðŸ“¦] install.txt generated at {req_output_path}")

        # # âœ… Install dependencies
        # pip_path = os.path.join(user_venv_path, "bin", "pip")
        # install_error = ''
        # res = subprocess.run([pip_path, "install", "-r", req_output_path], capture_output=True, text=True)
        # if res.returncode != 0:
        #     err = res.stderr.strip() or res.stdout.strip()
        #     logger.error(f"[âš ï¸] Some dependencies failed to install: {err}")
        #     install_error = f"Some dependencies failed to install: {err}"
        # else:
        #     logger.info(f"[âœ…] Dependencies installed in {user_venv_path}")
        #     print(f"[âœ…] Dependencies installed in {user_venv_path}")


        return {
            "status": "success",
            "path": script_path,
            "size": content_size,
            "script_id": script_id,
            "installed_path": req_output_path,
            "install_error": '',
            "log": f"Script {filename} uploaded successfully{'and dependencies file created as install.txt' } "
        }

    except Exception as e:
        print(f"[â›” upload_script error]: {e}")
        return {
            "status": "error",
            "log": f"Upload failed: {str(e)}"
        }



def _sanitize_part(part: str) -> str:
    part = re.sub(r'[^A-Za-z0-9._\- ]+', '_', part)
    return part.strip()

def _safe_join(base: str, *paths: str) -> str:
    final_path = os.path.abspath(os.path.join(base, *paths))
    base_abs = os.path.abspath(base)
    if not final_path.startswith(base_abs + os.sep) and final_path != base_abs:
        raise ValueError("Attempted path traversal")
    return final_path

async def _download_zip(session: aiohttp.ClientSession, url: str, max_bytes: int):
    temp = tempfile.NamedTemporaryFile(delete=False, suffix=".zip")
    total = 0
    try:
        async with session.get(url) as resp:
            resp.raise_for_status()
            clen = resp.headers.get("Content-Length")
            if clen is not None:
                try:
                    if int(clen) > max_bytes:
                        raise ValueError(f"Remote file too large ({clen} bytes). Limit is {max_bytes} bytes.")
                except Exception:
                    pass

            async for chunk in resp.content.iter_chunked(64 * 1024):
                if not chunk:
                    break
                total += len(chunk)
                if total > max_bytes:
                    raise ValueError(f"Downloaded file exceeds maximum size ({max_bytes} bytes).")
                temp.write(chunk)
        temp.flush()
        temp.close()
        return temp.name, total
    except Exception:
        try:
            temp.close()
            os.unlink(temp.name)
        except Exception:
            pass
        raise

def _safe_extract_zip(zip_path: str, dest_dir: str):
    extracted = []
    with zipfile.ZipFile(zip_path, 'r') as z:
        for info in z.infolist():
            name = info.filename
            if name.startswith('/') or name.startswith('\\'):
                raise ValueError("Absolute paths in zip are not allowed")
            parts = [p for p in pathlib.PurePosixPath(name).parts if p not in ('.', '')]
            if not parts:
                continue
            parts = [_sanitize_part(p) for p in parts]
            dest_path = _safe_join(dest_dir, *parts)
            if info.is_dir():
                os.makedirs(dest_path, exist_ok=True)
                continue
            parent = os.path.dirname(dest_path)
            os.makedirs(parent, exist_ok=True)
            with z.open(info, 'r') as srcf, open(dest_path, 'wb') as dstf:
                shutil.copyfileobj(srcf, dstf)
            try:
                # check first two bytes for shebang
                with open(dest_path, 'rb') as fh:
                    head = fh.read(2)
                if parts[-1].endswith(('.sh', '.py', '.pl')) or head == b'#!':
                    os.chmod(dest_path, 0o755)
            except Exception:
                pass
            rel = os.path.relpath(dest_path, dest_dir)
            extracted.append(rel)
    return extracted

def _gather_files_info(base_dir: str, relative_paths: list):
    """
    Build list of dicts: filename, file_path (rel), file_size (bytes), file_type (ext)
    Only includes files (not directories).
    """
    files = []
    for rel in relative_paths:
        full = os.path.join(base_dir, rel)
        if os.path.isfile(full):
            size = os.path.getsize(full)
            suffix = pathlib.Path(full).suffix or ''
            files.append({
                "filename": os.path.basename(full),
                "file_path": full,            # relative to returned path
                "file_size": size,
                "file_type": suffix
            })
    return files

@sio.on("upload_script_from_url")
async def on_upload_script_from_url(data):
    """
    Expecting:
    {
      "agent_id": "<user id>",
      "url": "https://.../archive.zip",
      "filename_hint": "optional-filename-or-root-folder-name"
    }
    """
    try:
        user_id = data['agent_id']
        url = data['url']
        filename_hint = data.get('filename_hint', 'uploaded_zip')

        # create unique script folder
        script_id = str(uuid.uuid4())
        script_dir = os.path.join(SCRIPT_DIR, user_id, script_id)
        os.makedirs(script_dir, exist_ok=True)

        logger = setup_logger(user_id, script_id, "run")
        logger.info(f"[ðŸ“¥] Downloading ZIP from URL: {url}")

        async with aiohttp.ClientSession() as session:
            try:
                zip_path, total_bytes = await _download_zip(session, url, MAX_FILE_SIZE_BYTES)
            except Exception as e:
                logger.error(f"[â›”] Download failed: {e}")
                return {
                    "status": "error",
                    "log": f"Download failed: {str(e)}"
                }

        logger.info(f"[ðŸ“¥] ZIP downloaded ({total_bytes} bytes) to temp: {zip_path}")

        try:
            if not zipfile.is_zipfile(zip_path):
                raise ValueError("Downloaded file is not a valid ZIP archive.")
        except Exception as e:
            try:
                os.unlink(zip_path)
            except Exception:
                pass
            logger.error(f"[â›”] Invalid ZIP: {e}")
            return {
                "status": "error",
                "log": f"Invalid ZIP archive: {str(e)}"
            }

        try:
            extracted_files = _safe_extract_zip(zip_path, script_dir)
        except Exception as e:
            try:
                shutil.rmtree(script_dir, ignore_errors=True)
            except Exception:
                pass
            try:
                os.unlink(zip_path)
            except Exception:
                pass
            logger.error(f"[â›”] Extraction failed: {e}")
            return {
                "status": "error",
                "log": f"Extraction failed: {str(e)}"
            }

        try:
            os.unlink(zip_path)
        except Exception:
            pass

        # Build files array with metadata
        files_meta = _gather_files_info(script_dir, extracted_files)

        logger.info(f"[âœ…] Extracted {len(extracted_files)} paths into {script_dir}")
        print(f"[ðŸ“¥] ZIP saved and extracted to: {script_dir} ({total_bytes} bytes)")

        return {
            "status": "success",
            "path": script_dir,
            "size": total_bytes,
            "script_id": script_id,
            "extracted_files": extracted_files,  # relative paths
            "files": files_meta,                 # detailed metadata
            "log": f"ZIP downloaded and extracted to {script_dir}"
        }

    except Exception as e:
        print(f"[â›” upload_script_from_url error]: {e}")
        return {
            "status": "error",
            "log": f"Upload-from-url failed: {str(e)}"
        }

@sio.on("upload_script_zip")
async def on_upload_script_zip(data):
    """
    Accepts only ZIP payloads:
    {
      "agent_id": "<user id>",
      "file_b64": "<BASE64 ZIP>",
      "filename_hint": "optional-root-folder-or-name",
      "size": 12345   # optional client hint
    }
    """
    try:
        user_id = data.get("agent_id")
        if not user_id:
            return {"status": "error", "log": "Missing 'agent_id'."}

        filename_hint = data.get("filename_hint", "uploaded_zip")
        client_size_hint = data.get("size")

        # Optional pre-check
        if isinstance(client_size_hint, int) and client_size_hint > MAX_FILE_SIZE_BYTES:
            return {"status": "error", "log": f"File too large (client-reported): {client_size_hint} bytes."}

        file_b64 = data.get("file_b64")
        if not file_b64:
            return {"status": "error", "log": "Missing 'file_b64' field."}

        # Decode base64
        try:
            zip_bytes = base64.b64decode(file_b64)
        except Exception as e:
            return {"status": "error", "log": f"Failed to decode base64: {str(e)}"}

        total_bytes = len(zip_bytes)
        if total_bytes == 0 or total_bytes > MAX_FILE_SIZE_BYTES:
            return {"status": "error", "log": f"File size invalid: {total_bytes} bytes."}

        # Create unique script folder
        script_id = str(uuid.uuid4())
        script_dir = os.path.join(SCRIPT_DIR, user_id, script_id)
        os.makedirs(script_dir, exist_ok=True)
        logger = setup_logger(user_id, script_id, "run")
        logger.info(f"[ðŸ“¥] Receiving ZIP payload ({total_bytes} bytes)")

        # Write temp ZIP
        temp_zip_path = os.path.join(tempfile.gettempdir(), f"{uuid.uuid4()}.zip")
        with open(temp_zip_path, "wb") as f:
            f.write(zip_bytes)

        # Validate ZIP
        if not zipfile.is_zipfile(temp_zip_path):
            os.unlink(temp_zip_path)
            shutil.rmtree(script_dir, ignore_errors=True)
            return {"status": "error", "log": "Uploaded file is not a valid ZIP."}

        # Extract safely
        extracted_files = _safe_extract_zip(temp_zip_path, script_dir)
        os.unlink(temp_zip_path)

        # Create venv per user
        user_venv_path = os.path.join(VENV_BASE_DIR, user_id)
        if not os.path.exists(user_venv_path):
            subprocess.run(["python3", "-m", "venv", user_venv_path], check=True)
            logger.info(f"[âœ…] Created venv for user: {user_id}")

        # Generate install.txt
        req_output_path = os.path.join(script_dir, "install.txt")

        # Gather metadata
        files_meta = _gather_files_info(script_dir, extracted_files)

        return {
            "status": "success",
            "path": script_dir,
            "size": total_bytes,
            "script_id": script_id,
            "extracted_files": extracted_files,
            "files": files_meta,
            "installed_path": req_output_path,
            "install_error": "",
            "log": f"ZIP '{filename_hint}' uploaded and extracted."
        }

    except Exception as e:
        try: shutil.rmtree(script_dir, ignore_errors=True)
        except Exception: pass
        return {"status": "error", "log": f"Upload failed: {str(e)}"}


# Helper: recursive copy that preserves metadata and optionally skips folders
def _copy_tree_preserve(src_dir, dst_dir, skip_dirs=None):
    skip_dirs = set(skip_dirs or [])
    for root, dirs, files in os.walk(src_dir):
        # compute relative path from src_dir
        rel_root = os.path.relpath(root, src_dir)
        # dest root
        dest_root = os.path.join(dst_dir, rel_root) if rel_root != "." else dst_dir
        os.makedirs(dest_root, exist_ok=True)

        # optionally skip some subdirectories (in-place modify dirs to prune walk)
        dirs[:] = [d for d in dirs if d not in skip_dirs]

        # copy files
        for fname in files:
            src_path = os.path.join(root, fname)
            dest_path = os.path.join(dest_root, fname)

            # create parent if missing
            os.makedirs(os.path.dirname(dest_path), exist_ok=True)

            # copy file with metadata
            shutil.copy2(src_path, dest_path)

            # preserve executable bit for scripts if set
            try:
                st = os.stat(src_path)
                os.chmod(dest_path, st.st_mode)
            except Exception:
                # ignore chmod failures
                pass

@sio.on("clone_script")
async def on_clone_script(data):
    try:
        user_id = data['agent_id']
        existing_script_id = data['existing_script_id']
        skip_venv = data.get("skip_venv", True)

        existing_script_dir = os.path.join(SCRIPT_DIR, user_id, existing_script_id)
        if not os.path.exists(existing_script_dir):
            return {
                "status": "error",
                "log": f"Existing script ID {existing_script_id} not found for user {user_id}"
            }

        # create new script folder
        new_script_id = str(uuid.uuid4())
        new_script_dir = os.path.join(SCRIPT_DIR, user_id, new_script_id)
        os.makedirs(new_script_dir, exist_ok=True)

        # directories to skip to avoid copying venvs/interpreter folders
        common_venv_names = {"venv", "venv3"}
        skip_dirs = common_venv_names if skip_venv else set()

        # perform recursive copy preserving metadata
        _copy_tree_preserve(existing_script_dir, new_script_dir, skip_dirs=skip_dirs)

        

        print(f"[ðŸ“„] Script cloned: {existing_script_id} â†’ {new_script_id} (full directory, no .py rename)")

        return {
            "status": "success",
            "script_id": new_script_id,
            "path": new_script_dir,
            "log": "Script directory cloned successfully (no .py renaming performed)"
        }

    except Exception as e:
        print(f"[â›” clone_script error]: {e}")
        return {
            "status": "error",
            "log": f"Clone failed: {str(e)}"
        }

@sio.on("run_dependency")
async def on_run_dependency(data):
    try:
        user_id = data['agent_id']
        script_dir = data['filepath']
        script_id = data.get('script_id', 'unknown')

        logger = setup_logger(AGENT_ID, script_id, "run")
        # âœ… Create venv (per-agent)
        user_venv_path = os.path.join(VENV_BASE_DIR, user_id)

        # âœ… Generate requirements.txt
        req_output_path = os.path.join(script_dir, "install.txt")
        generate_requirements(script_dir, req_output_path, logger)
        logger.info(f"[ðŸ“¦] install.txt generated at {req_output_path}")
        print(f"[ðŸ“¦] install.txt generated at {req_output_path}")

        # âœ… Install dependencies
        pip_path = os.path.join(user_venv_path, "bin", "pip")
        res=subprocess.run([pip_path, "install", "-r", req_output_path], capture_output=True, text=True)
        print(f"[âœ…] Dependencies installed in {user_venv_path}")
        logger.info(f"[âœ…] Dependencies installed in {user_venv_path}")
        if res.returncode != 0:
            err = res.stderr.strip() or res.stdout.strip()
            logger.exception(err)
            return {
                "status": "error",
                "log": f"run_dependency failed: {str(err)}"
                }
        return {
            "status": "success",
            "log": "[âœ…] Dependencies installed "
        }

    except Exception as e:
        print(f"[â›” run_dependency error]: {e}")
        logger.exception(f"[â›” run_dependency error]: {e}")
        return {
            "status": "error",
            "log": f"run_dependency failed: {str(e)}"
        }

@sio.on("run_install_dependency_r")
async def on_run_install_dependency_r(data):
    try:
        user_id = data['agent_id']
        script_dir = data['filepath']
        script_id = data.get('script_id', 'unknown')

        logger = setup_logger(AGENT_ID, script_id, "run")

        # âœ… Create venv (per-agent)
        user_venv_path = os.path.join(VENV_BASE_DIR, user_id)

        # âœ… Generate requirements file path
        req_output_path = os.path.join(script_dir, "install.txt")

        # ðŸ”Ž Check if file exists
        if not os.path.exists(req_output_path):
            msg = f"[â›”] install.txt not found at {req_output_path}"
            print(msg)
            logger.error(msg)
            return {
                "status": "error",
                "log": msg
            }

        # âœ… Install dependencies
        pip_path = os.path.join(user_venv_path, "bin", "pip")
        res = subprocess.run([pip_path, "install", "-r", req_output_path], capture_output=True, text=True)
        msg = f"[âœ…] Dependencies installed in {user_venv_path}"
        print(msg)
        logger.info(msg)
        if res.returncode != 0:
            err = res.stderr.strip() or res.stdout.strip()
            logger.exception(err)
            return {
                "status": "error",
                "log": f"run_dependency failed: {str(err)}"
            }
        return {
            "status": "success",
            "log": msg
        }

    except Exception as e:
        msg = f"[â›” run_dependency error]: {e}"
        print(msg)
        logger.exception(msg)
        return {
            "status": "error",
            "log": f"run_dependency failed: {str(e)}"
        }

async def _background_install(
    sio,
    *,
    user_id: str,
    script_dir: str,
    script_id: str,
    venv_base_dir: str,
    logger,
):
    try:
        user_venv_path = os.path.join(venv_base_dir, user_id)
        req_output_path = os.path.join(script_dir, "install.txt")

        if not os.path.exists(req_output_path):
            msg = f"[â›”] install.txt not found at {req_output_path}"
            logger.error(msg)
            await sio.emit("install_done", {
                "status": "error",
                "agent_id": user_id,
                "script_id": script_id,
                "log": msg,
            })
            return

        # Make sure the venv (and pip) exist
        pip_path = os.path.join(user_venv_path, "bin", "pip")

        cmd = [pip_path, "install", "-r", req_output_path]
        logger.info(f"[â–¶ï¸] Starting dependency install: {' '.join(cmd)}")

        # Run pip as an asyncio subprocess and stream combined stdout/stderr
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.STDOUT,
            cwd=script_dir,
            env={**os.environ, "PIP_DISABLE_PIP_VERSION_CHECK": "1"},
        )

        # Stream logs line-by-line
        assert proc.stdout is not None
        while True:
            line = await proc.stdout.readline()
            if not line:
                break
            text = line.decode(errors="replace").rstrip()
            if text:
                logger.info(text)
                await sio.emit("install_log", {
                    "agent_id": user_id,
                    "script_id": script_id,
                    "line": text
                })

        rc = await proc.wait()
        if rc == 0:
            msg = f"[âœ…] Dependencies installed in {user_venv_path}"
            logger.info(msg)
            await sio.emit("install_done", {
                "status": "success",
                "agent_id": user_id,
                "script_id": script_id,
                "log": msg
            })
        else:
            msg = f"[â›”] pip exited with code {rc}"
            logger.error(msg)
            await sio.emit("install_done", {
                "status": "error",
                "agent_id": user_id,
                "script_id": script_id,
                "log": msg
            })

    except Exception as e:
        msg = f"[â›” run_dependency error]: {e}"
        logger.exception(msg)
        await sio.emit("install_done", {
            "status": "error",
            "agent_id": user_id,
            "script_id": script_id,
            "log": msg
        })


@sio.on("run_install_dependency")
async def on_run_install_dependency(data):
    user_id = data["agent_id"]
    script_dir = data["filepath"]
    script_id = data.get("script_id", "unknown")

    logger = setup_logger(AGENT_ID, script_id, "run")

    # Fire-and-forget background task
    asyncio.create_task(_background_install(
        sio,
        user_id=user_id,
        script_dir=script_dir,
        script_id=script_id,
        venv_base_dir=VENV_BASE_DIR,
        logger=logger,
    ))

    # Return immediately
    return {
        "status": "success",
        "log": f"[ðŸš€] Dependencies installation started. Check logs for progress."
    }    

@sio.on("upload_file")
async def on_upload_file(data):
    try:
        path = data['path']
        filename = data['filename']
        file_bytes_b64 = data['file_bytes']  # base64 encoded binary

        # âœ… Decode base64 content
        import base64
        try:
            file_bytes = base64.b64decode(file_bytes_b64)
        except Exception as e:
            raise ValueError("Failed to decode base64 content") from e

        # âœ… File size check
        if len(file_bytes) > MAX_FILE_SIZE_BYTES:
            return {
                "status": "error",
                "log": f"File too large. Max allowed is {MAX_FILE_SIZE_KB} KB."
            }

        # âœ… Save file to disk
        script_dir = os.path.join(path)
        os.makedirs(script_dir, exist_ok=True)
        file_path = os.path.join(script_dir, filename)

        async with aiofiles.open(file_path, "wb") as f:
            await f.write(file_bytes)

        print(f"[ðŸ“¥] File saved: {filename} ({len(file_bytes)} bytes) at {file_path}")

        return {
            "status": "success",
            "path": file_path,
            "size": len(file_bytes),
            "filename": filename,
            "log": f"File '{filename}' uploaded successfully"
        }

    except Exception as e:
        print(f"[â›” upload_file error]: {e}")
        return {
            "status": "error",
            "log": f"Upload failed: {str(e)}"
        }
@sio.on("get_file")
async def on_get_file(data):
    try:
        filepath = data['filepath']

        # ðŸ” Validate path
        if ".." in filepath or not os.path.isfile(filepath):
            return {
                "status": "error",
                "log": f"Invalid file path: {filepath}"
            }

        # âœ… Read file content as text
        async with aiofiles.open(filepath, "r", encoding="utf-8") as f:
            content = await f.read()

        return {
            "status": "success",
            "filepath": filepath,
            "filename": os.path.basename(filepath),
            "content": content,
            "log": f"File '{os.path.basename(filepath)}' read successfully"
        }

    except Exception as e:
        print(f"[â›” get_file error]: {e}")
        return {
            "status": "error",
            "log": f"Read failed: {str(e)}"
        }

@sio.on("delete_file")
async def on_delete_file(data):
    try:
        path = data['path']
        is_folder = data.get('is_folder', False)

        # âœ… Construct full path
        target_path = path

        # âœ… Delete folder
        if is_folder:
            if not os.path.isdir(target_path):
                return {
                    "status": "error",
                    "log": f"Folder not found at '{target_path}'"
                }
            shutil.rmtree(target_path)
            print(f"[ðŸ—‘ï¸] Folder deleted: {target_path}")
            return {
                "status": "success",
                "log": f"Folder '{target_path}' deleted successfully",
                "path": target_path
            }

        # âœ… Delete file
        else:
            if not os.path.isfile(target_path):
                return {
                    "status": "error",
                    "log": f"File not found at '{target_path}'"
                }
            os.remove(target_path)
            print(f"[ðŸ—‘ï¸] File deleted: {target_path}")
            return {
                "status": "success",
                "log": f"File '{target_path}' deleted successfully",
                "path": target_path
            }

    except Exception as e:
        print(f"[â›” delete_file error]: {e}")
        return {
            "status": "error",
            "log": f"Delete failed: {str(e)}"
        }

# ==============================
# TERMINAL COMMAND HANDLER
# ==============================
@sio.on("exec_command")
async def on_exec_command(data):
    agent_id = data.get("agent_id", AGENT_ID)
    command = data.get("command")
    cwd = data.get("cwd", HOME_DIR)

    if not command:
        return {"status": "error", "log": "No command provided"}

    try:
        # Handle 'cd' manually
        if command.startswith("cd "):
            new_dir = command[3:].strip()
            new_cwd = os.path.abspath(os.path.join(cwd, new_dir))
            if os.path.isdir(new_cwd):
                cwd = new_cwd
                await sio.emit("command_output", {
                    "agent_id": agent_id,
                    "line": f"Changed directory to {cwd}",
                    "cwd": cwd,
                    "done": True
                })
                return {"status": "success", "cwd": cwd}
            else:
                await sio.emit("command_output", {
                    "agent_id": agent_id,
                    "line": f"[â›”] No such directory: {new_dir}",
                    "cwd": cwd,
                    "done": True
                })
                return {"status": "error", "cwd": cwd}

        # Run subprocess
        process = await asyncio.create_subprocess_shell(
            command,
            cwd=cwd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        # Stream stdout
        while True:
            line = await process.stdout.readline()
            if not line:
                break
            await sio.emit("command_output", {
                "agent_id": agent_id,
                "line": line.decode().rstrip(),
                "cwd": cwd
            })

        # Stream stderr
        while True:
            line = await process.stderr.readline()
            if not line:
                break
            await sio.emit("command_output", {
                "agent_id": agent_id,
                "line": "[â›”] " + line.decode().rstrip(),
                "cwd": cwd
            })

        await process.wait()
        await sio.emit("command_output", {
            "agent_id": agent_id,
            "line": f"[âœ”] Command finished with code {process.returncode}",
            "cwd": cwd,
            "done": True
        })

        return {"status": "success", "cwd": cwd}

    except Exception as e:
        await sio.emit("command_output", {
            "agent_id": agent_id,
            "line": f"[â›”] {str(e)}",
            "cwd": cwd,
            "done": True
        })
        return {"status": "error", "cwd": cwd, "log": str(e)}
    
@sio.on("run_script")
async def on_run_script(data):
    filepath = data['filepath']
    script_id = data.get('script_id', 'unknown')
    logger = setup_logger(AGENT_ID, script_id, "run")
    try:
        print(f"[â–¶ï¸] Running script: {filepath}")
        user_id = data.get('agent_id', AGENT_ID)
        user_venv_path = os.path.join(VENV_BASE_DIR, user_id)
        python_bin = os.path.join(user_venv_path, "bin", "python")

        #result = subprocess.run([python_bin, filepath], capture_output=True, text=True)
         # Start subprocess (non-blocking)
      # Async subprocess
        process = await asyncio.create_subprocess_exec(
            python_bin, filepath,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        stdout, stderr = await process.communicate()
        output = (stdout.decode() if stdout else "") + "\n" + (stderr.decode() if stderr else "")
        status = "script_done" if process.returncode == 0 else "script_failed"

        logger.info("=== Script Run ===\n%s", output.strip())
        print(f"[ðŸ“œ] Script output: {output.strip()}")
        print(f"[âœ…] Script finished with return code: {process.returncode}{status}")
        await sio.emit(status, {
            "agent_id": AGENT_ID,
            "script_id": script_id,
            "return_code": process.returncode,
            "log": output[-500:],  # limit log size
            "timestamp": datetime.utcnow().isoformat()
        })
    except Exception as e:
        logger.exception("Script run failed")
        print(f"[â›” run_script error]: {e}")
        return {
            "status": "error",
            "log": f"Run failed: {e}"
        }

@sio.on("setup_cron")
async def on_setup_cron(data):
    filepath = data['filepath']
    script_id = data.get('script_id', 'unknown')
    
    try:
        cron_expr = data['cron']
        cron_name = f"{datetime.now().strftime('%Y%m%d%H%M%S')}_{uuid.uuid4().hex[:6]}"
        job_id = f"{AGENT_ID}_{script_id}_{cron_name}"
        logger = setup_logger(AGENT_ID, script_id,"cron",job_id)
        cron = CronTab(user=True)
        cron.remove_all(comment=job_id)
        user_id = data.get('agent_id', AGENT_ID)
        user_venv_path = os.path.join(VENV_BASE_DIR, user_id)
        python_bin = os.path.join(user_venv_path, "bin", "python")
        log_path = os.path.join(LOG_BASE_DIR, job_id, 'cron.log')

        command = f"{python_bin} {filepath} >> {log_path} 2>&1"

        job = cron.new(command=command, comment=job_id)
        job.setall(cron_expr)
        cron.write()

        print(f"[ðŸ•’] Cron job added for {script_id}: {cron_expr}")
        logger.info("Cron setup: %s", cron_expr)
        return {
            "status": "success",
            "log": f"Cron job set: {cron_expr}",
            "job_id": job_id
        }
    except Exception as e:
        logger.exception("Cron setup failed")
        print(f"[â›” setup_cron error]: {e}")
        return {
            "status": "error",
            "log": f"Setup cron failed: {e}"
        }

@sio.on("remove_cron")
async def on_remove_cron(data):
    script_id = data['script_id']
    job_id = data['job_id']
    logger = setup_logger(AGENT_ID, script_id, "run")
    try:
        cron = CronTab(user=True)
        cron.remove_all(comment=job_id)
        cron.write()

        print(f"[ðŸ—‘ï¸] Cron job removed: {job_id}")
        logger.info("Cron job removed")
        await on_delete_file({
            "path": os.path.join(LOG_BASE_DIR, job_id),
            "is_folder": True
        })  # Clean up logs
        return {
            "status": "success",
            "log": "Cron job removed"
        }
    except Exception as e:
        logger.exception("Cron removal failed")
        print(f"[â›” remove_cron error]: {e}")
        return {
            "status": "error",
            "log": f"Remove cron failed: {e}"
        }

@sio.on("toggle_cron")
async def on_toggle_cron(data):
    script_id = data['script_id']
    job_id = data['job_id']
    action = data['action']  # "pause" or "play"
    logger = setup_logger(AGENT_ID, script_id, "cron", job_id)

    try:
        cron = CronTab(user=True)
        modified = False

        for job in cron:
            if job.comment == job_id:
                if action == "pause" and job.enabled:
                    job.enable(False)  # Comment out
                    logger.info("Cron job paused")
                    print(f"[â¸ï¸] Cron job paused: {job_id}")
                elif action == "play" and not job.enabled:
                    job.enable(True)  # Uncomment
                    logger.info("Cron job resumed")
                    print(f"[â–¶ï¸] Cron job resumed: {job_id}")
                else:
                    logger.info(f"Cron job already in desired state: {action}")
                modified = True
                break

        if modified:
            cron.write()
            return {
                "status": "success",
                "log": f"Cron job {action}d"
            }
        else:
            return {
                "status": "error",
                "log": "Cron job not found"
            }

    except Exception as e:
        logger.exception("Toggle cron failed")
        print(f"[â›” toggle_cron error]: {e}")
        return {
            "status": "error",
            "log": f"Toggle cron failed: {e}"
        }
    

@sio.on("setup_background")
async def on_setup_background(data):
    filepath = data['filepath']
    script_id = data.get('script_id', 'unknown')
    user_id = data.get('agent_id', AGENT_ID)
    
    job_id = f"{AGENT_ID}_{script_id}_{uuid.uuid4().hex[:6]}"
    logger = setup_logger(AGENT_ID, script_id, "pm2", job_id)

    user_venv_path = os.path.join(VENV_BASE_DIR, user_id)
    python_bin = os.path.join(user_venv_path, "bin", "python")

    log_path = os.path.join(LOG_BASE_DIR, job_id, 'pm2.log')
    os.makedirs(os.path.dirname(log_path), exist_ok=True)

    # PM2 process name
    process_name = f"{PM2_PROCESS_PREFIX}_{job_id}"

    try:
        command = [
            "pm2", "start", python_bin,
            "--name", process_name,
            "--log", log_path,
            "--", filepath
        ]
        subprocess.run(command, check=True)

        logger.info("PM2 background task started.")
        return {
            "status": "success",
            "log": f"PM2 background task started with process: {process_name}",
            "job_id": job_id,
            "process_name": process_name
        }

    except subprocess.CalledProcessError as e:
        logger.error("PM2 setup failed: %s", str(e))
        return {
            "status": "error",
            "log": f"Failed to start PM2 background task: {str(e)}"
        }    


@sio.on("remove_pm2")
async def on_remove_pm2(data):
    script_id = data['script_id']
    job_id = data['job_id']
    logger = setup_logger(AGENT_ID, script_id, "run", job_id)
    try:
        # Stop and delete the PM2 process
        subprocess.run(["pm2", "delete", f"{PM2_PROCESS_PREFIX}_{job_id}"], check=True)
        print(f"[ðŸ—‘ï¸] PM2 process removed: {job_id}")
        logger.info("PM2 process removed")

        # Clean up logs
        await on_delete_file({
            "path": os.path.join(LOG_BASE_DIR, job_id),
            "is_folder": True
        })

        return {
            "status": "success",
            "log": "PM2 process removed"
        }

    except Exception as e:
        logger.exception("PM2 removal failed")
        print(f"[â›” remove_pm2 error]: {e}")
        return {
            "status": "error",
            "log": f"Remove PM2 process failed: {e}"
        }

@sio.on("toggle_pm2")
async def on_toggle_pm2(data):
    script_id = data['script_id']
    job_id = data['job_id']
    action = data['action']  # "pause" or "play"
    logger = setup_logger(AGENT_ID, script_id, "pm2", job_id)

    try:
        if action == "pause":
            subprocess.run(["pm2", "stop", f"{PM2_PROCESS_PREFIX}_{job_id}"], check=True)
            logger.info("PM2 process paused")
            print(f"[â¸ï¸] PM2 process paused: {job_id}")
        elif action == "play":
            subprocess.run(["pm2", "start", f"{PM2_PROCESS_PREFIX}_{job_id}"], check=True)
            logger.info("PM2 process resumed")
            print(f"[â–¶ï¸] PM2 process resumed: {job_id}")
        else:
            return {
                "status": "error",
                "log": f"Unknown action '{action}'"
            }

        return {
            "status": "success",
            "log": f"PM2 process {action}d"
        }

    except Exception as e:
        logger.exception("Toggle PM2 failed")
        print(f"[â›” toggle_pm2 error]: {e}")
        return {
            "status": "error",
            "log": f"Toggle PM2 failed: {e}"
        }



import sqlite3

@sio.on("get_tables")
async def on_get_tables(data):
    db_path = data.get("db_path")
    if not db_path:
        return {"status": "error", "message": "Missing db_path"}
        

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = [row[0] for row in cursor.fetchall()]
        conn.close()

        return {"status": "success", "tables": tables}

    except Exception as e:
        return  {"status": "error", "message": str(e)}

@sio.on("get_table_data")
async def on_get_table_data(data):
    db_path = data.get("db_path")
    table_name = data.get("table")

    if not db_path or not table_name:
       return {"status": "error", "message": "Missing db_path or table"}
        

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute(f"SELECT * FROM {table_name} LIMIT 100;")
        rows = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]
        conn.close()

        return {
            "status": "success",
            "columns": columns,
            "rows": rows,
            "table": table_name
        }

    except Exception as e:
        return {"status": "error", "message": str(e)}

@sio.on("get_logs")
async def on_get_logs(data):
    try:
        script_id = data['script_id']
        mode = data.get('mode', 'run')
        log_file = os.path.join(LOG_BASE_DIR, AGENT_ID, script_id, f"{mode}.log")
        if os.path.exists(log_file):
            with open(log_file, "r") as f:
                content = f.read()
        else:
            content = "[!] Log file not found"
        print(f"[ðŸ“œ] Sending logs for script_id={script_id}")
        return {
            "status": "success",
            "log": content[-1000:]
        }
    except Exception as e:
        print(f"[â›” get_logs error]: {e}")
        return {
            "status": "error",
            "log": f"Get logs failed: {e}"
        }


@sio.on("get_metrics")
async def on_get_metrics(data):
    try:
        metrics = {}
        is_exist = data['is_exist']
        if  is_exist:
            metrics = {
                "cpu": psutil.cpu_percent(interval=0),
                "memory": psutil.virtual_memory().percent,
                "disk": psutil.disk_usage("/").percent,
                "agent_id": AGENT_ID
            }
        else:
            db_path = init_credentials_db(HOME_DIR)
            print("DB path:", db_path)
            metrics = {
                "cpu": psutil.cpu_percent(interval=0),
                "memory": psutil.virtual_memory().percent,
                "disk": psutil.disk_usage("/").percent,
                "agent_id": AGENT_ID,
                "root_dir": HOME_DIR,
                "script_dir": SCRIPT_DIR,
                "venv_base_dir": VENV_BASE_DIR,
                "db_path": db_path,
                "log_base_dir": LOG_BASE_DIR
            }
        print("âœ… Sent metrics")
        return metrics
    except Exception as e:
        print(f"[â›” get_metrics error]: {e}")
        return {
            "status": "error",
            "log": f"Get metrics failed: {e}"
        }

# === START ===
async def start():
    try:
        await sio.connect(SERVER_URL)
        await sio.wait()
    except Exception as e:
        print(f"[ðŸš«] Could not connect to server: {e}")

@sio.on("exec_command")
async def on_exec_command(data):
    agent_id = data.get("agent_id", AGENT_ID)
    command = data.get("command")
    cwd = data.get("cwd", HOME_DIR)

    if not command:
        return {"status": "error", "log": "No command provided"}

    try:
        # Handle 'cd' manually
        if command.startswith("cd "):
            new_dir = command[3:].strip()
            new_cwd = os.path.abspath(os.path.join(cwd, new_dir))
            if os.path.isdir(new_cwd):
                cwd = new_cwd
                await sio.emit("command_output", {
                    "agent_id": agent_id,
                    "line": f"Changed directory to {cwd}",
                    "cwd": cwd,
                    "done": True
                })
                return {"status": "success", "cwd": cwd}
            else:
                await sio.emit("command_output", {
                    "agent_id": agent_id,
                    "line": f"[â›”] No such directory: {new_dir}",
                    "cwd": cwd,
                    "done": True
                })
                return {"status": "error", "cwd": cwd}

        # Run subprocess
        process = await asyncio.create_subprocess_shell(
            command,
            cwd=cwd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        # Stream stdout
        while True:
            line = await process.stdout.readline()
            if not line:
                break
            await sio.emit("command_output", {
                "agent_id": agent_id,
                "line": line.decode().rstrip(),
                "cwd": cwd
            })

        # Stream stderr
        while True:
            line = await process.stderr.readline()
            if not line:
                break
            await sio.emit("command_output", {
                "agent_id": agent_id,
                "line": "[â›”] " + line.decode().rstrip(),
                "cwd": cwd
            })

        await process.wait()
        await sio.emit("command_output", {
            "agent_id": agent_id,
            "line": f"[âœ”] Command finished with code {process.returncode}",
            "cwd": cwd,
            "done": True
        })

        return {"status": "success", "cwd": cwd}

    except Exception as e:
        await sio.emit("command_output", {
            "agent_id": agent_id,
            "line": f"[â›”] {str(e)}",
            "cwd": cwd,
            "done": True
        })
        return {"status": "error", "cwd": cwd, "log": str(e)}

# --------------------------------------------------------------------
# Helpers
# --------------------------------------------------------------------
def _now_iso() -> str:
    return datetime.utcnow().isoformat() + "Z"

def _connect(db_path: str):
    return sqlite3.connect(db_path, timeout=30, isolation_level=None)

# --------------------------------------------------------------------
# DB setup
# --------------------------------------------------------------------
def init_credentials_db(folder_path: str, db_filename: str = DEFAULT_DB_FILENAME) -> str:
    """
    Create a credentials DB under folder_path.
    Tables:
      - credentials(id, label, exchange, api_key_masked, secret_blob, metadata_json, created_at, updated_at)
      - audit_log(id, cred_id, action, context, timestamp)
    """
    folder = Path(folder_path)
    folder.mkdir(parents=True, exist_ok=True)
    db_path = folder / db_filename

    conn = sqlite3.connect(str(db_path))
    cur = conn.cursor()

    cur.execute("""
    CREATE TABLE IF NOT EXISTS credentials (
        id TEXT PRIMARY KEY,
        label TEXT,
        exchange TEXT,
        api_key_masked TEXT,
        api_key TEXT,
        secret_blob BLOB,
        metadata_json TEXT,
        created_at TEXT,
        updated_at TEXT
    );
    """)

    cur.execute("""
    CREATE TABLE IF NOT EXISTS audit_log (
        id TEXT PRIMARY KEY,
        cred_id TEXT,
        action TEXT,
        context TEXT,
        timestamp TEXT
    );
    """)

    conn.commit()
    conn.close()

    try:
        os.chmod(db_path, 0o600)
    except Exception:
        pass

    return str(db_path)

# --------------------------------------------------------------------
# Mask helper
# --------------------------------------------------------------------
def mask_api_key(api_key: Optional[str], head: int = 4, tail: int = 4) -> str:
    if not api_key:
        return ""
    n = len(api_key)
    if n <= head + tail:
        return api_key[0:head] + "*" * (n - head)
    return api_key[:head] + "****" + api_key[-tail:]

# --------------------------------------------------------------------
# CRUD
# --------------------------------------------------------------------
def save_credential(db_path: str,
                    label: str,
                    exchange: str,
                    api_key: Optional[str],
                    api_secret_blob: bytes,
                    metadata: Optional[Dict[str, Any]] = None) -> str:
    cred_id = uuid.uuid4().hex
    masked = mask_api_key(api_key or "")
    meta_json = json.dumps(metadata or {}, default=str)
    now = _now_iso()

    conn = _connect(db_path)
    cur = conn.cursor()
    # check existing (label + exchange)
    cur.execute("SELECT id FROM credentials WHERE exchange=? and label=?", (exchange,label,))
    if cur.fetchone():
        conn.close()
        raise ValueError(f"Credential for exchange '{exchange}' and label '{label}' already exists.")

    cur.execute("""
      INSERT INTO credentials (label, exchange, api_key, api_key_masked, secret_blob, metadata_json, created_at, updated_at)
      VALUES ( ?, ?, ?, ?, ?, ?, ?,?)
    """, (label, exchange, api_key, masked, sqlite3.Binary(api_secret_blob), meta_json, now, now))
    conn.commit()
    conn.close()

    log_audit(db_path, cred_id, "create", json.dumps({"label": label, "exchange": exchange}))
    return cred_id


def update_credential_secret(db_path: str, label: str, exchange: str, secret_blob: bytes,api_key: Optional[str],):
    conn = _connect(db_path)
    cur = conn.cursor()
    cur.execute("SELECT id FROM credentials WHERE exchange=? and label=?", (exchange,label,))
    if cur.fetchone() is None:
        conn.close()
        raise KeyError("Credential not found")
    cur.execute("UPDATE credentials SET secret_blob=?, api_key=?, updated_at=? WHERE exchange=?",
                (sqlite3.Binary(secret_blob), api_key,_now_iso(), exchange))
    conn.commit()
    conn.close()
    log_audit(db_path, exchange, "update_secret", "")


def get_credential(db_path: str, exchange: str,label: str) -> Optional[Dict[str, Any]]:
    conn = _connect(db_path)
    cur = conn.cursor()
    cur.execute("""
      SELECT id, label, exchange, api_key_masked, secret_blob, metadata_json, created_at, updated_at
      FROM credentials WHERE exchange=? and label=?
    """, (exchange,label,))
    row = cur.fetchone()
    conn.close()
    if not row:
        return None
    return {
        "id": row[0],
        "label": row[1],
        "exchange": row[2],
        "api_key_masked": row[3],
        "secret_blob": row[4],
        "metadata": json.loads(row[5] or "{}"),
        "created_at": row[6],
        "updated_at": row[7]
    }


def list_credentials(db_path: str) -> List[Dict[str, Any]]:
    conn = _connect(db_path)
    cur = conn.cursor()
    cur.execute("""
      SELECT id, label, exchange, api_key_masked, metadata_json, created_at, updated_at
      FROM credentials ORDER BY created_at DESC
    """)
    rows = cur.fetchall()
    conn.close()
    return [{
        "id": r[0],
        "label": r[1],
        "exchange": r[2],
        "api_key_masked": r[3],
        "metadata": json.loads(r[4] or "{}"),
        "created_at": r[5],
        "updated_at": r[6],
    } for r in rows]


def delete_credentialdb(db_path: str,label: str, exchange: str):
    conn = _connect(db_path)
    cur = conn.cursor()
    cur.execute("DELETE FROM credentials WHERE exchange=? and label=?", (exchange,label,))
    conn.commit()
    conn.close()
    log_audit(db_path, label, "delete", "")


def log_audit(db_path: str, cred_id: str, action: str, context: str = ""):
    conn = _connect(db_path)
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO audit_log (id, cred_id, action, context, timestamp)
        VALUES (?, ?, ?, ?, ?)
    """, (uuid.uuid4().hex, cred_id, action, context, _now_iso()))
    conn.commit()
    conn.close()

# --------------------------------------------------------------------
# RSA key utilities
# --------------------------------------------------------------------
def load_rsa_private_key(path: str):
    """Load private RSA key (PEM) for decryption."""
    with open(path, "rb") as f:
        data = f.read()
    return serialization.load_pem_private_key(data, password=None)


def load_rsa_public_key(path: str):
    """Load public RSA key (PEM) for encryption."""
    with open(path, "rb") as f:
        data = f.read()
    return serialization.load_pem_public_key(data)


def encrypt_rsa_with_public_key(pub_key, plaintext: str) -> bytes:
    """Encrypt string -> ciphertext bytes using public key (RSA-OAEP SHA256)."""
    return pub_key.encrypt(
        plaintext.encode("utf-8"),
        padding.OAEP(
            mgf=padding.MGF1(algorithm=hashes.SHA256()),
            algorithm=hashes.SHA256(),
            label=None
        )
    )


def decrypt_rsa_blob(priv_key, blob: bytes) -> bytes:
    """Decrypt ciphertext bytes -> plaintext bytes using private key."""
    return priv_key.decrypt(
        blob,
        padding.OAEP(
            mgf=padding.MGF1(algorithm=hashes.SHA256()),
            algorithm=hashes.SHA256(),
            label=None
        )
    )

# --------------------------------------------------------------------
# Utility
# --------------------------------------------------------------------
def get_db_path_for_folder(folder_path: str, db_filename: str = DEFAULT_DB_FILENAME) -> str:
    p = Path(folder_path) / db_filename
    if not p.exists():
        raise FileNotFoundError(f"No DB found at {p}")
    return str(p)



    # # example plaintext
    # payload = '{"api_key":"TEST1234","api_secret":"MYSECRET"}'
    # cipher = encrypt_rsa_with_public_key(pub, payload)
    # cid = save_credential(db_path, "demo", "binance", "TEST1234", cipher)
    # print("Saved credential:", cid)


    # cred = get_credential(db_path, cid)
    # print("Decrypted:", decrypt_rsa_blob(priv, cred["secret_blob"]).decode())
# === MAIN ===
pub = load_rsa_public_key(pub_path)
priv = load_rsa_private_key(priv_path)

@sio.on("get_public_key")
async def get_public_key(data):
    try:
       pub = Path(pub_path)

       if not pub:
            return {
            "status": "error",
            "log": f"Public key file not found"
        }

       return {
            "status": "success",
            "pem": pub.read_text()
        }
    except Exception as e:
        return {
            "status": "error",
            "log": f"Public key not found : {e}"

    
        }
    
def safe_base64_decode(b64: str) -> bytes:
    try:
        # validate=True raises if invalid characters/padding
        return base64.b64decode(b64, validate=True)
    except Exception as e:
        # Some clients produce URL-safe base64 (replace -,_ -> +,/ and pad), attempt that fallback:
        try:
            b64_fixed = b64.replace("-", "+").replace("_", "/")
            # pad
            padding_needed = (4 - len(b64_fixed) % 4) % 4
            b64_fixed += "=" * padding_needed
            return base64.b64decode(b64_fixed, validate=True)
        except Exception:
            raise ValueError(f"Invalid base64 ciphertext: {e}")
        
@sio.on("get_credentialInfo")
async def get_credentialInfo(data):
    logger = setup_logger(AGENT_ID, data['exchange'], "run")
    try:
       folder = Path(HOME_DIR)
       db_path = folder / DEFAULT_DB_FILENAME       
       priv = load_rsa_private_key(priv_path)
       cred = get_credential(db_path,data['exchange'], data['label'])
       print("Decrypted:", decrypt_rsa_blob(priv, cred["secret_blob"]))


       return {
            "status": "success",
            "bytes": decrypt_rsa_blob(priv, cred["secret_blob"]),
            "ap_key_masked": cred["api_key_masked"]
        }
    except Exception as e:
        logger.exception("PM2 removal failed")
        print(f"[â›” remove_pm2 error]: {e}")
        return {
            "status": "error",
            "log": f"Remove PM2 process failed: {e}"
        }

@sio.on("add_exchange_credential")
async def add_exchange_credential(data):
    logger = setup_logger(AGENT_ID, data['exchange'], "run")
    try:
       folder = Path(HOME_DIR )
       cipher_bytes = safe_base64_decode(data['api_secret_blob'])
       save_credential(
            db_path=folder / DEFAULT_DB_FILENAME,
            label=data['label'],
            exchange=data['exchange'],
            api_key=data['api_key'],
            api_secret_blob=cipher_bytes,
            metadata=data.get('metadata', {})
        )
       logger.info("Credential added for exchange: %s", data['exchange'])


       return {
            "status": "success",
            "log": "Credential added"
        }
    except Exception as e:
        logger.exception("credential add failed")
        return {
            "status": "error",
            "log": f"Add credential failed: {e}"
        }
    
@sio.on("updateexchange_credential")
async def updateexchange_credential(data):
    logger = setup_logger(AGENT_ID, data['exchange'], "run")
    try:
       folder = Path(HOME_DIR)
       db_path = folder / DEFAULT_DB_FILENAME 
       update_credential_secret(
            db_path,
            label=data['label'],
            exchange=data['exchange'],
            api_key=data['api_key'],
            api_secret_blob=data['api_secret_blob'].encode('latin1'),
        )
       logger.info("Credential added for exchange: %s", data['exchange'])


       return {
            "status": "success",
            "log": "Credential updated"
        }
    except Exception as e:
        logger.exception("Update db failed")
        return {
            "status": "error",
            "log": f"Update failed: {e}"
        }

@sio.on("delete_credential")
async def delete_credential(data):
    logger = setup_logger(AGENT_ID, data['exchange'], "run")
    try:
       folder = Path(HOME_DIR)
       db_path = folder / DEFAULT_DB_FILENAME 
       delete_credentialdb(
            db_path,
            label=data['label'],
            exchange=data['exchange']
        )
       logger.info("Credential deleted for exchange: %s", data['exchange'])


       return {
            "status": "success",
            "log": "Credential deleted"
        }
    except Exception as e:
        logger.exception("Update db failed")
        return {
            "status": "error",
            "log": f"Update failed: {e}"
        }
async def download_and_extract_script(agent_id: str, url: str):
    """
    Returns: script_dir, script_id
    Raises exception on failure
    """
    script_id = str(uuid.uuid4())
    script_dir = os.path.join(SCRIPT_DIR, agent_id, script_id)
    os.makedirs(script_dir, exist_ok=True)

    async with aiohttp.ClientSession() as session:
        zip_path, total_bytes = await _download_zip(
            session,
            url,
            MAX_FILE_SIZE_BYTES
        )

    if not zipfile.is_zipfile(zip_path):
        os.unlink(zip_path)
        raise ValueError("Downloaded file is not a valid ZIP")

    _safe_extract_zip(zip_path, script_dir)
    os.unlink(zip_path)

    return script_dir, script_id

@sio.on("deploy_script")
async def deploy_script(data):
    logger = None
    task_id = data.get("task_id")

    try:
        agent_id = data["agent_id"]
        config = data.get("config", {})
        pm2_enabled = True

        script_source = data.get("script_source", "local")

        # ðŸ”½ NEW: resolve script_path dynamically
        if script_source == "url":
            await sio.emit("deploy_progress", {
                "task_id": task_id,
                "level": "INFO",
                "source": "system",
                "log": "Downloading script from URL..."
            })

            script_path, script_id = await download_and_extract_script(
                agent_id,
                data["url"]
            )
            script_name = script_id
        else:
            script_name = data["script_name"]
            script_path = data["script_path"]

        logger = setup_logger(agent_id, script_name, "deploy")
        logger.info(f"[ðŸš€] Starting deployment for {script_name}")

        await sio.emit("deploy_progress", {
            "task_id": task_id,
            "level": "INFO",
            "source": "system",
            "log": "Deployment started"
        })

        # 1ï¸âƒ£ Create .env
        env_path = os.path.join(script_path, ".env")
        with open(env_path, "w") as f:
            for k, v in config.items():
                f.write(f"{k}={v}\n")

        await sio.emit("deploy_progress", {
            "task_id": task_id,
            "level": "INFO",
            "source": "system",
            "log": ".env file created"
        })

        # 2ï¸âƒ£ Install dependencies
        install_txt = os.path.join(script_path, "install.txt")
        if os.path.exists(install_txt):
            venv_path = os.path.join(VENV_BASE_DIR, agent_id)
            pip_bin = os.path.join(venv_path, "bin", "pip")

            if not os.path.exists(venv_path):
                subprocess.run(["python3", "-m", "venv", venv_path], check=True)

            proc = subprocess.Popen(
                [pip_bin, "install", "-r", install_txt],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True
            )

            for line in proc.stdout:
                await sio.emit("deploy_progress", {
                    "task_id": task_id,
                    "level": "INFO",
                    "source": "agent",
                    "log": line.strip()
                })

            proc.wait()
            if proc.returncode != 0:
                raise RuntimeError("Dependency installation failed")

        # 3ï¸âƒ£ PM2 start
        job_id = None
        process_name = None

        if pm2_enabled:
            main_script = (
                os.path.join(script_path, "main.py")
                if os.path.exists(os.path.join(script_path, "main.py"))
                else next(
                    (os.path.join(script_path, f)
                     for f in os.listdir(script_path)
                     if f.endswith(".py")),
                    None
                )
            )

            if not main_script:
                raise RuntimeError("No Python entry file found")

            job_id = f"{agent_id}_{uuid.uuid4().hex[:6]}"
            python_bin = os.path.join(VENV_BASE_DIR, agent_id, "bin", "python")
            process_name = f"{PM2_PROCESS_PREFIX}_{job_id}"

            proc = subprocess.Popen(
                ["pm2", "start", python_bin, "--name", process_name, "--", main_script],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True
            )

            for line in proc.stdout:
                await sio.emit("deploy_progress", {
                    "task_id": task_id,
                    "level": "INFO",
                    "source": "agent",
                    "log": line.strip()
                })

            proc.wait()
            if proc.returncode != 0:
                raise RuntimeError("PM2 start failed")

        await sio.emit("deploy_done", {
            "task_id": task_id,
            "job_id": job_id,
            "process_name": process_name,
            "message": "Deployment completed successfully"
        })

    except Exception as e:
        if logger:
            logger.error(str(e))

        await sio.emit("deploy_failed", {
            "task_id": task_id,
            "error": str(e)
        })


if __name__ == "__main__":
    asyncio.run(start())
      # demo: create db, encrypt/decrypt with RSA keys
    # db_path = init_credentials_db(HOME_DIR)
